# -*- coding: utf-8 -*-
"""recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13ErnwuUEDrwuUwX6oPIAzRNk3Qxb9g6g
"""

import pandas as pd
import numpy as np
import re
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
from wordcloud import WordCloud
import random
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""# **Data Loading**
Menggunakan dua dataset, yaitu dataset lagu yang nantinya disebut dataset track dan riwayat lagu yang didengarkan disebut dataset user.
Dataset track berisi 114.000 baris dengan 20 kolom tentang detail informasi lagu seperti judul, artis, genre, tempo, dll. Sedangkan dataset user berisi 149.860 baris dan 11 kolom tentang riwayat lagu yang didengarkan lengkap dengan informasi seperti ID lagu, judul, durasi mendengarkan, dll.

Sumber dataset diperoleh dari website [Kaggle](https://kaggle.com/)
- [Dataset track](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)
- [Dataset user](https://www.kaggle.com/datasets/sgoutami/spotify-streaming-history)
"""

from google.colab import drive
drive.mount('/content/drive')

track = pd.read_csv('/content/drive/My Drive/Dicoding ML Terapan/Kedua/spotify_songs.csv')
track.drop('Unnamed: 0', axis=1, inplace=True)
track.head()

track.info()

"""Penjelasan kolom-kolom dataset track

* track_id: ID lagu pada spotify
* artists: Artis yang menyanyikan lagu. Jika lebih dari satu dipisahkan dengan ";"
* album_name: Nama album dari lagu
* track_name: Judul lagu
* popularity : Nilai popularitas lagu dalam skala 0-100
* duration_ms: Durasi lagu dalam *milisecond*
* explicit: Penanda apakah lagu mengandung lirik eksplisit (kasar)
* danceability: Nilai kecocokan lagu digunakan untuk dansa, antara 0 dan 1. Semakin tinggi semakin cocok untuk berdansa
* energy: Nilai seberapa intens energi dalam lagu, antara 0 dan 1. Semakin tinggi semakin kuat dan bersemangat
* key: Nada dasar lagu, contoh 0=C, 1=C♯/D♭, dst.
* loudness: Nilai seberapa keras lagu dalam desibel (dB)
* mode: Tangga nada lagu, 1 untuk mayor, 0 untuk minor
* speechiness: Nilai seberapa banyak perkataan dalam lagu, antara 0 dan 1. Semakin tinggi menunjukkan banyak perkataan daripada nyanyian dalam lagu
* acousticness: Nilai seberapa akustik lagu, antara 0 dan 1
* instrumentalness: Nilai seberapa vokal dalam lagu, antara 0 dan 1. Semakin tinggi semakin tidak ada vokal
* liveness: Nilai adanya penonton dalam lagu, antara 0 dan 1. Semakin tinggi menunjukkan lagu dimainkan secara langsung (*live*)
* valence: Nilai emosi dalam lagu, antara 0 dan 1. Semakin tinggi nilai menunjukkan emosi lagu positif
* tempo: Jumlah ketukan (*beat*) lagu dalam *beats per minute* (BPM)
* time_signature: Tanda birama lagu
* track_genre: Genre lagu
"""

user = pd.read_csv('/content/drive/My Drive/Dicoding ML Terapan/Kedua/spotify_history.csv')
user.head()

user.info()

"""Penjelasan kolom-kolom dataset user

* spotify_track_uri: ID lagu pada spotify
* track_name: Judul lagu
* artist_name: Artis yang menyanyikan lagu
* album_name: Nama album dari lagu
* ts: Waktu ketika lagu selesai diputar, dalam format yyyy-MM-dd HH:mm:ss
* platform: Platfrom yang digunakan untuk mendengarkan lagu
* ms_played: Durasi putar lagu dalam *milisecond*
* reason_start: Alasan mulai memutar lagu
* reason_end: Alasan berhenti memutar lagu
* shuffle: Penanda apakah lagu diputar dalam mode acak
* skipped: Penanda apakah lagu dilewati (*skip*) oleh pengguna

**Missing value**

Memeriksa jumlah data kosong pada kedua dataset. Data-data kosong ini akan dihilangkan.
"""

track_null = track.isnull().sum()
track_null[track_null > 0]

user_null = user.isnull().sum()
user_null[user_null > 0]

"""**Duplicate Value**

Pemeriksaan berapa banyak data duplikat pada kedua dataset. Data duplikat ini juga akan dihilangkan dari dataset
"""

print(f'{track.duplicated().sum()} data duplikat pada track')
print(f'{user.duplicated().sum()} data duplikat pada user')

"""Proses menghapus data kosong dan duplikat pada dataset track dan user. Tersisa 113.549 baris pada datset track dan 148.463 baris pada dataset user."""

track.dropna(inplace=True)
track.drop_duplicates(inplace=True)
user.dropna(inplace=True)
user.drop_duplicates(inplace=True)
print(f'Track shape: {track.shape}, User shape: {user.shape}')

"""Memeriksa baris track dengan 'track_id' yang sama. Terdapat beberapa lagu yang memiliki ID duplikat."""

dup_id = track.duplicated(subset=['track_id'], keep=False)
dup_id.sum()

"""Memeriksa salah satu lagu dengan ID  '5SuOikwiRyPMVoIQDJUgSV'. Ternyata dalam satu lagu bisa memiliki banyak genre"""

idx_dup_id = dup_id[dup_id == True].index
df_dup = track.loc[idx_dup_id]
df_dup = df_dup[df_dup['track_id'] == '5SuOikwiRyPMVoIQDJUgSV']
df_dup[['track_id', 'artists', 'track_name', 'track_genre']]

"""Memeriksa jumlah data lagu pada dataset track dengan duplikasi pada beberapa kolom untuk mendeteksi lagu yang identik."""

dup_track = track.duplicated(subset=['artists', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'], keep=False)
dup_track.sum()

"""Contoh pemeriksaan terhadap data lagu berjudul "I'm Yours". Terlihat bahwa data lagu dengan judul dan artis yang sama juga terduplikat dan memiliki ID yang berbeda."""

idx_dup_id = dup_track[dup_track == True].index
df_dup = track.loc[idx_dup_id]
df_dup = df_dup[df_dup['track_name'] == "I'm Yours"]
df_dup[['track_id', 'artists', 'track_name', 'track_genre']]

"""Menghilangkan data lagu yang identik berdasarkan kolom-kolom yang ditentukan. Proses ini menyisakan 83.908 baris pada dataset track."""

track_uniq = track.drop_duplicates(subset=['artists', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'])
track_uniq.shape

"""**Data Filtering**

Memilih sebagian baris saja dari dataset. Untuk dataset track hanya menggunakan lagu dengan nilai 'popularity' di atas 60. Sedangkan dataset user disaring hanya untuk ID lagu yang terdapat pada dataset track yang sudah disaring.

Proses ini menyisakan 9.488 baris pada dataset track dan 22.413 baris pada dataset user.
"""

track_uniq = track_uniq[track_uniq['popularity'] >= 60]
track_uniq.shape

user_isin = user[user['spotify_track_uri'].isin(track_uniq['track_id'].values)]
user_isin = user_isin.rename(columns={'spotify_track_uri': 'track_id'})
user_isin.shape

"""# **Exploratory Data Analysis**

Pemetaan genre dengan jumlah lagu terbanyak pada dataset track menggunakan Wordcloud dan diagram batang. Genre k-pop, pop-film dan hip-hop menjadi yang paling banyak.
"""

genres = track_uniq['track_genre'].value_counts()
genres.index

cloud = WordCloud(
    width=640,
    height=640,
    background_color='white',
    min_font_size=10
).generate_from_frequencies(genres.to_dict())
plt.imshow(cloud, interpolation = 'nearest')
plt.axis('off')
plt.show()

genres[:10].plot(kind='barh', figsize=(8,6))

"""Analisis diagram batang genre yang paling sering didengarkan berdasarkan dataset user. Genre british cukup dominan dibanding genre lain."""

track_merged = track_uniq.groupby('track_id')['track_genre'].agg(list).reset_index()
user_genres = pd.merge(user_isin, track_merged, on='track_id', how='left')
genres = Counter()
for i, row in user_genres.iterrows():
    for j in row['track_genre']:
        genres[j] += row['ms_played'] / (1e3 * 60 * 60)

user_genres_dur = pd.DataFrame.from_dict(genres, orient='index').reset_index()
user_genres_dur = user_genres_dur.rename(columns = {'index': 'genre', 0: 'ms_played'})
user_genres_dur.set_index('genre', inplace=True)
user_genres_dur = user_genres_dur.sort_values('ms_played', ascending=False)
user_genres_dur[:10].plot(kind='barh', figsize=(8,6))
plt.ylabel('Genre')
plt.xlabel('Durasi (jam)')
plt.legend().remove()
plt.show()

"""Analisis ditribusi data pada dataset track menggunakan histogram.

- Semakin tinggi popularitas, semakin sedikit jumlah lagu
- Dataset didominasi oleh lagu penuh nyanyian (speechiness rendah), bukan instrumental (instrumental rendah), bukan lagu akustik (acousticness rendah), serta tidak ditampilkan secara *live* (liveness rendah)
- Hampir seluruh lagu memiliki tanda birama 4/4 yang umum digunakan pada lagu pop. Hal ini bisa terjadi karena dataset track telah disaring menjadi hanya lagu-lagu populer
- Distribusi key hampir merata, dengan pengecualian nada dasar D# yang lebih kecil dari nada dasar lain
- Durasi lagu, valence, danceability, dinamika, serta tempo terdistribusi normal
"""

track_uniq.hist(bins=50, figsize=(20,15))
plt.show()

"""# **Data Preparation**

**Formatting**

Menggabungkan data beberapa genre dalam satu lagu menjadi satu string
"""

track_merged = track.groupby('track_id')['track_genre'].agg(list).reset_index()
track_prep = track_uniq.drop('track_genre', axis=1)
track_prep = track_prep.merge(track_merged, on='track_id')
track_prep['track_genre'] = track_prep['track_genre'].apply(lambda x:' '.join(x))
track_prep['track_genre'] = [re.sub(r'-', '', t) for t in track_prep['track_genre']]

"""**Feature Engineering**

Membangun kolom 'content' untuk dataset track dari kolom 'speechiness', 'instrumentalness', 'tempo', 'mode', 'loudness', dan 'explicit'.
"""

def get_speech_content(row):
    speech = row['speechiness']
    return 'speech' if speech > 0.66 else 'music'

def get_instrumental_content(row):
    mode = row['instrumentalness']
    return 'instrumental' if mode > 0.85 else 'vocal'

def get_explicit_content(row):
    return 'explicit' if row['explicit'] else 'clean'

def get_mode_content(row):
    mode = row['mode']
    return 'major' if mode == 1 else 'minor'

def get_loudness_content(row):
    loudness = row['loudness']

    if loudness > -7:
        return 'stentorian'
    elif loudness > -11:
        return 'loud'
    elif loudness > -14:
        return 'normal'
    else:
        return 'quiet'

def get_tempo_content(row):
    tempo = row['tempo']

    if tempo < 40:
        return 'grave'
    elif tempo < 45:
        return 'lento'
    elif tempo < 55:
        return 'largo'
    elif tempo < 65:
        return 'adagio'
    elif tempo < 69:
        return 'adagietto'
    elif tempo < 77:
        return 'andante'
    elif tempo < 98:
        return 'moderato'
    elif tempo < 109:
        return 'allegretto'
    elif tempo < 132:
        return 'allegro'
    elif tempo < 140:
        return 'vivace'
    elif tempo < 177:
        return 'presto'
    else:
        return 'prestissimo'

track_prep['content'] = track_prep.apply(get_speech_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep.apply(get_instrumental_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep.apply(get_tempo_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep.apply(get_mode_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep.apply(get_loudness_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep.apply(get_explicit_content, axis=1)
track_prep['content'] = track_prep['content'] + ' ' + track_prep['track_genre']

track_prep.head()

"""Membuat matriks numerik dari fitur 'content' pada dataset track dengan metode TF-IDF (Term Frequency-Inverse Document Frequency)."""

tf_idf = TfidfVectorizer()
tf_idf.fit(track_prep['content'])
tf_idf.get_feature_names_out()

tfidf_matrix = tf_idf.fit_transform(track_prep['content'])
tfidf_matrix = tfidf_matrix.astype(np.float32)
tfidf_matrix.shape

tfidf_matrix.todense()

df_tfidf = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf_idf.get_feature_names_out(),
    index=track_prep['track_name']
)
df_tfidf.sample(10, axis=1).sample(10, axis=0)

"""Membuat 180 ID pengguna secara acak pada dataset user"""

def set_user_id(row):
    user_id = str(row['user_id'])
    rem_len = 5 - len(user_id)
    return f'U{"0" * rem_len}{user_id}'

user_merged = pd.merge(user_isin, track_prep, on='track_id', how='inner')
user_merged['user_id'] = [random.randint(1, 180) for _ in range(len(user_merged))]
user_merged['user_id'] = user_merged.apply(set_user_id, axis=1)
user_merged.head()

"""**Data Merging**

Akumulasi durasi mendengarkan dengan ID pengguna dan ID lagu yang sama
"""

user_merged.duplicated(subset=['track_id', 'user_id']).sum()

user_prep = user_merged.groupby(['track_id', 'user_id'])['ms_played'].agg(sum).reset_index()
user_prep.shape

user_prep = user_merged[['track_id', 'user_id', 'ms_played']]
user_prep.head()

"""**Encoding**

Mengubah ID user dan ID lagu pada dataset user ke dalam urutan angka dari 1 hingga jumlah ID yang ada, yaitu 180.
"""

user_ids = user_prep['user_id'].unique().tolist()
user_to_code = {x: i for i, x in enumerate(user_ids)}
code_to_user = {i: x for i, x in enumerate(user_ids)}

track_ids = user_prep['track_id'].unique().tolist()
track_to_code = {x: i for i, x in enumerate(track_ids)}
code_to_track = {i: x for i, x in enumerate(track_ids)}

"""**Scaling**

Mengubah semua nilai 'ms_played' pada dataset user dalam skala antara 0 dan 1
"""

user_prep['user'] = user_prep['user_id'].map(user_to_code)
user_prep['track'] = user_prep['track_id'].map(track_to_code)
user_prep['ms_played'] = user_prep['ms_played'].values.astype(np.float32)
user_prep = user_prep.sample(frac=1, random_state=42)
user_prep.head()

"""**Train-test Split**

Dataset user dibagi menjadi data training dan validation dengan proporsi 80:20.
"""

min_ms = min(user_prep['ms_played'])
max_ms = max(user_prep['ms_played'])

x = user_prep[['user', 'track']].values
y = user_prep['ms_played'].apply(lambda x: (x - min_ms) / (max_ms - min_ms)).values
train_indices = int(0.8 * user_prep.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""# **Model Development**

**Cosine Similarity**

Membangun model rekomendasi *content-based filtering* yang memberikan rekomendasi berdasarkan konten dari item yang diinputkan. Kesamaan antar item dihitung menggunakan cosine similarity, berdasarkan matriks TF-IDF yang sudah dibuat.
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim_df = pd.DataFrame(cosine_sim, index=track_prep['track_id'], columns=track_prep['track_id'])
print('Shape:', cosine_sim_df.shape)
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def recommendations(track_id, similarity_data=cosine_sim_df, items=track_prep, k=5):
    sim = similarity_data.loc[:, track_id].to_numpy()
    idx_range = range(-1, -k, -1)
    index = sim.argpartition(idx_range)
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    scores =  sim[index[-1:-(k+2):-1]]

    df_closest = pd.DataFrame(closest).merge(items, on='track_id')
    df_closest = df_closest[['track_id', 'artists', 'track_name', 'content']]

    df_closest['score'] = scores
    df_closest.set_index('track_id', inplace=True)
    df_closest.drop(track_id, errors='ignore', inplace=True)
    df_closest.sort_values('score', ascending=False, inplace=True)
    return df_closest.head()

"""Percobaan sistem *content-based filtering* dengan ID lagu '10rChmECwPcvTTj4w07hq4'."""

track_prep[track_prep['track_id'] == '10rChmECwPcvTTj4w07hq4']

"""Hasil rekomendasi content-based filtering yang menampilkan 5 lagu serupa dengan lagu ID '10rChmECwPcvTTj4w07hq4'"""

cb_rec = recommendations('10rChmECwPcvTTj4w07hq4')
cb_rec

"""**Dot Product**

Membangun model rekomendasi *collaborative filtering* yang memberikan rekomendasi berdasarkan kemiripan item dengan pengguna lainnya
"""

class RecommenderNet(keras.Model):
    def __init__(self, num_users, num_tracks, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_tracks = num_tracks
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.track_embedding = layers.Embedding(
            num_tracks,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.track_bias = layers.Embedding(num_tracks, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:,0])
        user_bias = self.user_bias(inputs[:, 0])
        track_vector = self.track_embedding(inputs[:, 1])
        track_bias = self.track_bias(inputs[:, 1])

        dot_user_track = tf.tensordot(user_vector, track_vector, 2)
        x = dot_user_track + user_bias + track_bias
        return tf.nn.sigmoid(x)

num_users = len(user_to_code)
num_tracks = len(track_to_code)

model = RecommenderNet(num_users, num_tracks, 50)
model.compile(
    loss = keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 10,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Pengujian model *collaborative filtering* untuk pengguna dengan ID 'U00007'"""

def get_user_tracks(id):
    user_track = user_merged[user_merged['user_id'] == id]
    user_track = user_track.sort_values('ms_played', ascending=False)
    return user_track[['track_id', 'artists', 'track_name_x', 'track_genre', 'ms_played']]

"""Menampilkan riwayat lagu yang didengarkan oleh pengguna"""

user_track = get_user_tracks('U00007')
user_track.head()

"""Pemetaan genre yang paling lama didengar oleh pengguna"""

user_genres = Counter()
for i, row in user_track.iterrows():
    for j in row['track_genre'].split(' '):
        user_genres[j] += row['ms_played']

user_genres_ms = pd.DataFrame.from_dict(user_genres, orient='index').reset_index()
user_genres_ms = user_genres_ms.rename(columns = {'index': 'genre', 0: 'ms_played'})
user_genres_ms.set_index('genre', inplace=True)
user_genres_ms = user_genres_ms.sort_values('ms_played', ascending=False)
user_genres_ms[:5]

"""Hasil rekomendasi *collaborative filtering* untuk pengguna ID 'U00007'"""

user_id = 'U00007'
user_history = user_prep[user_prep['user_id'] == user_id]
track_not_listened = track_prep[~track_prep['track_id'].isin(user_history['track_id'].values)]['track_id']
track_not_listened = list(set(track_not_listened).intersection(set(track_to_code.keys())))
track_code_not_listened = [[track_to_code.get(x)] for x in track_not_listened]

user_code = user_to_code.get(user_id)
user_track_array = np.hstack(
    ([[user_code]] * len(track_code_not_listened), track_code_not_listened)
)

pred_ms = model.predict(user_track_array).flatten()
pred_ms_indices = pred_ms.argsort()[-5:][::-1]
rec_track_ids = [
    code_to_track.get(track_code_not_listened[x][0]) for x in pred_ms_indices
]

rec_user_track = track_prep[track_prep['track_id'].isin(rec_track_ids)]
rec_user_track[['track_id', 'artists', 'track_name', 'track_genre']]

"""# **Model Evaluation**

Evaluasi model *content-based filtering* dengan metrik Precision at K dengan hasil **1.0**
"""

cb_track = track_prep[track_prep['track_id'] == '10rChmECwPcvTTj4w07hq4']
cb_track_content = cb_track['content'].values[0]
cb_relevant = cb_rec[cb_rec['content'] == cb_track_content]
print(f"Precision at 5: {len(cb_relevant)/5}")

"""Evaluasi model *collaborative filtering* dengan metrik Root Mean Squared Error (RMSE) dengan hasil **177.973,790** ms (≈3 menit)."""

pred_val = model.predict(x_val).flatten()
mse_val = mean_squared_error(y_true=y_val, y_pred=pred_val)
scaled_rmse_val = np.sqrt(mse_val)
rmse_val = (scaled_rmse_val * (max_ms - min_ms)) + min_ms
rmse_val= '{0:.3f}'.format(rmse_val)
print(f"RMSE: {rmse_val}")